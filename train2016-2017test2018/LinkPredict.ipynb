{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4svK7xD75iFn"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "coau_df = pd.read_csv(\"data/coauthorsCG-edges.csv\",delimiter=\";\")\n",
    "#El dataset solo contiene edges del  2015 al  2019\n",
    "\n",
    "G = nx.from_pandas_edgelist(coau_df,\"Source\",\"Target\",['Weight','year'],create_using=nx.Graph())\n",
    "nodos = list(G.nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_component_subgraphs(G):\n",
    "    for c in nx.connected_components(G):\n",
    "        yield G.subgraph(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "coau_df2 = coau_df[coau_df[\"year\"]<2018]\n",
    "G2 = nx.from_pandas_edgelist(coau_df2,\"Source\",\"Target\",['Weight','year'],create_using=nx.Graph())\n",
    "nodos2 = list(G2.nodes)\n",
    "nodosNuevos = set(nodos)-set(nodos2)\n",
    "print(len(nodosNuevos))#Cantidad de nodos nuevos en el 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XFEF4a7B59vB",
    "outputId": "6b42fffc-b605-4a0f-e1bf-02ae442f91bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71159, 4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obteniendo dataframe de pares de nodos que no tienen coneccion\n",
    "\n",
    "adj_G = nx.to_numpy_matrix(G, nodelist = nodos)\n",
    "all_unconnected_pairs = []\n",
    "\n",
    "offset = 0\n",
    "for i in range(adj_G.shape[0]):\n",
    "  for j in range(offset,adj_G.shape[1]):\n",
    "    if i != j and adj_G[i,j] == 0:\n",
    "        all_unconnected_pairs.append((nodos[i],nodos[j]))\n",
    "\n",
    "  offset = offset + 1\n",
    "\n",
    "node_1_unlinked = [i[0] for i in all_unconnected_pairs]\n",
    "node_2_unlinked = [i[1] for i in all_unconnected_pairs]\n",
    "\n",
    "#Creando dataframe para almacenar a los pares de nodos no conectados que se recogieron\n",
    "data = pd.DataFrame({'Source':node_1_unlinked,'Target':node_2_unlinked})\n",
    "data['Weight'] = 0\n",
    "data['link'] = 0\n",
    "\n",
    "indices = range(len(data['Source']))\n",
    "\n",
    "#Separando el dataframe en datos para train y para test\n",
    "\n",
    "noRemoveIn,removeIn = train_test_split(indices,test_size=0.30,random_state=32)\n",
    "\n",
    "test= data.copy()\n",
    "test = test.drop(index=noRemoveIn)\n",
    "\n",
    "data = data.drop(index=removeIn)\n",
    "\n",
    "data.shape #Cantidad de ejemplos negativos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2QjyvRRv-S_z",
    "outputId": "55ef1059-d3ca-4795-f77c-184f6fbda45e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1175/1175 [00:04<00:00, 278.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(71922, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trabajando con los pares de nodos que si estan conectados\n",
    "\n",
    "#Obteniendo lista de los links que se pueden borrar (que no eliminan nodos, o dividen al grafo en mas de una componente) y que\n",
    "#estan despues del año establecido\n",
    "\n",
    "year = 2018\n",
    "initial_node_count = len(G.nodes)\n",
    "\n",
    "coau_df_temp = coau_df.copy()\n",
    "\n",
    "omissible_links_index = []\n",
    "for i in tqdm(coau_df.index.values):\n",
    "    if G.adj[coau_df.values[i,0]][coau_df.values[i,1]]['year']>=year:\n",
    "        # Eliminar una arista y construir un nuevo grafo sin esa unica arista\n",
    "        G_temp = nx.from_pandas_edgelist(coau_df_temp.drop(index=i), \"Source\", \"Target\",[\"Weight\"], create_using=nx.Graph())\n",
    "\n",
    "        # Verificando que al eliminar este par, no parte el grafo, y que el numero de nodos siga siendo el mismo\n",
    "\n",
    "        if (nx.number_connected_components(G_temp) == 1) and (len(G_temp.nodes) == initial_node_count):\n",
    "            omissible_links_index.append(i)\n",
    "            coau_df_temp = coau_df_temp.drop(i)\n",
    "\n",
    "#creando dataframe de edges que se pueden remover\n",
    "\n",
    "coau_df_temp2 = coau_df.copy()\n",
    "coau_df_temp2[\"link\"]=1\n",
    "\n",
    "#Separando dataframe en datos para train y test\n",
    "\n",
    "testlinks = coau_df_temp2.loc[omissible_links_index]\n",
    "coau_df_temp = coau_df_temp2.drop(index=omissible_links_index)\n",
    "\n",
    "data = data.append(coau_df_temp[['Source', 'Target', 'link','Weight']], ignore_index=True)\n",
    "data[\"Weight\"] = data[\"Weight\"].astype('int64')\n",
    "\n",
    "test = test.append(testlinks[['Source', 'Target', 'link','Weight']], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlSTGQd4Ajnx"
   },
   "outputs": [],
   "source": [
    "#Definiendo varias metricas para link prediction\n",
    "\n",
    "def commonNeighbors(G,source,target):\n",
    "    adj = dict(G.adj[source])\n",
    "    adj2 = dict(G.adj[target])\n",
    "    commonNeighbors = set(adj.keys()) & set(adj2.keys())\n",
    "    return commonNeighbors\n",
    "\n",
    "def jaccardCoeff(G,source,target):\n",
    "    adj = dict(G.adj[source])\n",
    "    adj2 = dict(G.adj[target])\n",
    "    unionNeighbors = set(adj.keys()) | set(adj2.keys())\n",
    "    commonNeighbors = set(adj.keys()) & set(adj2.keys())\n",
    "    return len(commonNeighbors)/len(unionNeighbors)\n",
    "\n",
    "def adamicAdar(G,source,target):\n",
    "    cn = commonNeighbors(G,source,target)\n",
    "    coeff = 0\n",
    "    for neighbor in cn:\n",
    "        coeff += 1/np.log(len(dict(G.adj[neighbor]).keys()))\n",
    "    return coeff\n",
    "\n",
    "def similarity(G,source,target):\n",
    "    adj = dict(G.adj[source])\n",
    "    adj2 = dict(G.adj[target])\n",
    "    y=0.5\n",
    "    val = 0\n",
    "    for a in set(adj.keys()):\n",
    "        for b in set(adj2.keys()):\n",
    "            if a==b:\n",
    "                val+= 1\n",
    "            else:\n",
    "                val+= similarity(G,a,b)\n",
    "    return val/(len(adj.keys())*len(adj2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfUY09Hw-hyY"
   },
   "outputs": [],
   "source": [
    "#Creando nuevo grafo sin los links eliminados aleatoriamente\n",
    "G_data = nx.from_pandas_edgelist(coau_df_temp, \"Source\", \"Target\",[\"Weight\"], create_using=nx.Graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w9IKZxaRYnwO",
    "outputId": "a7f4e812-7788-48d3-8612-7d7eacd475e2"
   },
   "outputs": [],
   "source": [
    "#Obteniendo las features, y armando los arrays para usarlo en la regresion logistica\n",
    "\n",
    "Xtrain =[]\n",
    "Ytrain =[]\n",
    "for i in data.values:\n",
    "    Xtrain.append([len(commonNeighbors(G_data,i[0],i[1])),adamicAdar(G_data,i[0],i[1])])\n",
    "    Ytrain.append(i[3])\n",
    "\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "for i in test.values:\n",
    "    Xtest.append([len(commonNeighbors(G_data,i[0],i[1])),adamicAdar(G_data,i[0],i[1])])\n",
    "    Ytest.append(i[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "01Xj5JJkh5hB",
    "outputId": "47df9b30-d245-4f1f-d0c0-bbe2e332ed86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresion logistica 0.8202119434953176\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "lr.fit(Xtrain, Ytrain)\n",
    "\n",
    "predictions = lr.predict(Xtest)\n",
    "print(\"Regresion logistica\",roc_auc_score(Ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2oMUtEyviIMo",
    "outputId": "3e093d0e-cf57-4e13-ff16-b1a1cb6f6e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos totales: 0.9688763790481737\n",
      "unos acertados: 0.6674757281553398\n",
      "ceros acertados: 0.9729481588352953\n"
     ]
    }
   ],
   "source": [
    "# Accuracy de varios tipos de aciertos \n",
    "\n",
    "aciertosTotales = 0\n",
    "unosAcertados = 0\n",
    "cerosAcertados = 0\n",
    "\n",
    "suma = 0\n",
    "for tst, y in zip(Xtest,Ytest):\n",
    "\n",
    "    predic = lr.predict([tst])[0]    \n",
    "    if y == predic:\n",
    "        aciertosTotales+=1\n",
    "        \n",
    "    if y == 1 and predic == 1:\n",
    "        unosAcertados+=1\n",
    "    #if tst[0]!= 0 and tst[1]!=0 and y==1:\n",
    "    #    suma+=1\n",
    "    if y == 0 and predic ==0:\n",
    "        cerosAcertados+=1\n",
    "\n",
    "acc = aciertosTotales/len(Ytest)\n",
    "print(\"Aciertos totales:\",acc)\n",
    "\n",
    "acc2 = unosAcertados/sum(Ytest)\n",
    "print(\"unos acertados:\",acc2)\n",
    "\n",
    "acc3 = cerosAcertados/(len(Ytest)-sum(Ytest))\n",
    "print(\"ceros acertados:\",acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:  0.5191387597888827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='scale')\n",
    "\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "predictions = clf.predict(Xtest)\n",
    "print(\"SVM: \",roc_auc_score(Ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LinkPrediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
