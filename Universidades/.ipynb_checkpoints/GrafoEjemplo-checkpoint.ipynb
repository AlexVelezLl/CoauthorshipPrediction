{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4svK7xD75iFn"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLcuyFGJj2KH"
   },
   "outputs": [],
   "source": [
    "#Definiendo varias metricas para link prediction\n",
    "def commonNeighbors(G,source,target):\n",
    "  adj = dict(G.adj[source])\n",
    "  adj2 = dict(G.adj[target])\n",
    "  commonNeighbors = set(adj.keys()) & set(adj2.keys())\n",
    "  return commonNeighbors\n",
    "\n",
    "def jaccardCoeff(G,source,target):\n",
    "  adj = dict(G.adj[source])\n",
    "  adj2 = dict(G.adj[target])\n",
    "  unionNeighbors = set(adj.keys()) | set(adj2.keys())\n",
    "  commonNeighbors = set(adj.keys()) & set(adj2.keys())\n",
    "  return len(commonNeighbors)/len(unionNeighbors)\n",
    "\n",
    "def adamicAdar(G,source,target):\n",
    "  cn = commonNeighbors(G,source,target)\n",
    "  coeff = 0\n",
    "  for neighbor in cn:\n",
    "    if len(dict(G.adj[neighbor]).keys()) >1:\n",
    "      coeff += 1/np.log(len(dict(G.adj[neighbor]).keys()))\n",
    "  return coeff\n",
    "\n",
    "def similarity(G,source,target):\n",
    "    adj = dict(G.adj[source])\n",
    "    adj2 = dict(G.adj[target])\n",
    "    y=0.5\n",
    "    val = 0\n",
    "    for a in set(adj.keys()):\n",
    "        for b in set(adj2.keys()):\n",
    "            if a==b:\n",
    "                val+= 1\n",
    "            else:\n",
    "                val+= similarity(G,a,b)\n",
    "    return val/(len(adj.keys())*len(adj2.keys()))\n",
    "\n",
    "def commonKeywords(nodes_df,source,target):\n",
    "  keywords1 = list(nodes_df[nodes_df[\"ID\"]==source][\"KeywordsB2018\"])\n",
    "  keywords1 = set(str(keywords1[0]).split(\",\"))\n",
    "  keywords2 = list(nodes_df[nodes_df[\"ID\"]==target][\"KeywordsB2018\"])\n",
    "  keywords2 = set(str(keywords2[0]).split(\",\"))\n",
    "  common = keywords1 & keywords2\n",
    "  return len(common)\n",
    "\n",
    "#Contador binario\n",
    "def contador(l):\n",
    "    acarreo =True\n",
    "    for i in range(len(l)):\n",
    "        if(acarreo):\n",
    "            l[i] = not(l[i])\n",
    "            acarreo = l[i]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2162129,
     "status": "ok",
     "timestamp": 1589242909123,
     "user": {
      "displayName": "Alex Velez Llaque",
      "photoUrl": "",
      "userId": "11111465116901712450"
     },
     "user_tz": 300
    },
    "id": "vcGo_UIujrrC",
    "outputId": "af8ced83-716b-475f-d235-d6aa6d27e92d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Universidades:   0%|                                                                             | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                         | 0/1156 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|█▍                                                                             | 21/1156 [00:00<00:05, 204.36it/s]\u001b[A\n",
      "  3%|██▌                                                                            | 38/1156 [00:00<00:05, 191.57it/s]\u001b[A\n",
      "  5%|███▉                                                                           | 57/1156 [00:00<00:05, 188.42it/s]\u001b[A\n",
      "  6%|████▉                                                                          | 73/1156 [00:00<00:06, 177.27it/s]\u001b[A\n",
      "  8%|██████                                                                         | 88/1156 [00:00<00:06, 166.57it/s]\u001b[A\n",
      "  9%|███████                                                                       | 104/1156 [00:00<00:06, 160.22it/s]\u001b[A\n",
      " 11%|████████▋                                                                     | 128/1156 [00:00<00:05, 177.30it/s]\u001b[A\n",
      " 13%|█████████▊                                                                    | 145/1156 [00:00<00:05, 168.80it/s]\u001b[A\n",
      " 14%|███████████▎                                                                  | 167/1156 [00:00<00:05, 179.24it/s]\u001b[A\n",
      " 16%|████████████▍                                                                 | 185/1156 [00:01<00:05, 174.58it/s]\u001b[A\n",
      " 18%|█████████████▋                                                                | 203/1156 [00:01<00:05, 166.55it/s]\u001b[A\n",
      " 19%|██████████████▊                                                               | 220/1156 [00:01<00:05, 157.74it/s]\u001b[A\n",
      " 20%|███████████████▉                                                              | 236/1156 [00:01<00:08, 109.56it/s]\u001b[A\n",
      " 22%|█████████████████                                                              | 250/1156 [00:01<00:13, 65.00it/s]\u001b[A\n",
      " 23%|█████████████████▊                                                             | 261/1156 [00:02<00:14, 60.28it/s]\u001b[A\n",
      " 23%|██████████████████▍                                                            | 270/1156 [00:02<00:13, 64.51it/s]\u001b[A\n",
      " 24%|███████████████████▎                                                           | 282/1156 [00:02<00:11, 74.38it/s]\u001b[A\n",
      " 25%|███████████████████▉                                                           | 292/1156 [00:02<00:11, 78.35it/s]\u001b[A\n",
      " 26%|████████████████████▋                                                          | 302/1156 [00:02<00:10, 77.80it/s]\u001b[A\n",
      " 27%|█████████████████████▋                                                         | 317/1156 [00:02<00:09, 90.48it/s]\u001b[A\n",
      " 29%|██████████████████████▌                                                        | 330/1156 [00:02<00:08, 98.94it/s]\u001b[A\n",
      " 30%|███████████████████████▎                                                      | 345/1156 [00:02<00:07, 108.82it/s]\u001b[A\n",
      " 31%|████████████████████████▎                                                     | 361/1156 [00:03<00:06, 118.84it/s]\u001b[A\n",
      " 33%|██████████████████████████                                                    | 386/1156 [00:03<00:05, 140.39it/s]\u001b[A\n",
      " 35%|███████████████████████████▏                                                  | 403/1156 [00:03<00:05, 139.16it/s]\u001b[A\n",
      " 36%|████████████████████████████▎                                                 | 419/1156 [00:03<00:05, 144.14it/s]\u001b[A\n",
      " 38%|█████████████████████████████▍                                                | 436/1156 [00:03<00:04, 150.14it/s]\u001b[A\n",
      " 39%|██████████████████████████████▊                                               | 456/1156 [00:03<00:04, 161.46it/s]\u001b[A\n",
      " 41%|████████████████████████████████                                              | 476/1156 [00:03<00:04, 169.52it/s]\u001b[A\n",
      " 43%|█████████████████████████████████▎                                            | 494/1156 [00:03<00:03, 171.66it/s]\u001b[A\n",
      " 44%|██████████████████████████████████▌                                           | 512/1156 [00:03<00:04, 152.58it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▋                                          | 529/1156 [00:04<00:04, 146.94it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████                                         | 549/1156 [00:04<00:03, 157.87it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████▎                                       | 568/1156 [00:04<00:03, 164.69it/s]\u001b[A\n",
      " 51%|███████████████████████████████████████▍                                      | 585/1156 [00:04<00:03, 152.13it/s]\u001b[A\n",
      " 52%|████████████████████████████████████████▌                                     | 601/1156 [00:04<00:03, 150.18it/s]\u001b[A\n",
      " 54%|█████████████████████████████████████████▊                                    | 619/1156 [00:04<00:03, 155.49it/s]\u001b[A\n",
      " 55%|██████████████████████████████████████████▊                                   | 635/1156 [00:04<00:03, 139.08it/s]\u001b[A\n",
      " 56%|███████████████████████████████████████████▊                                  | 650/1156 [00:04<00:03, 138.75it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████▊                                 | 665/1156 [00:05<00:03, 130.92it/s]\u001b[A\n",
      " 59%|█████████████████████████████████████████████▊                                | 679/1156 [00:05<00:03, 123.40it/s]\u001b[A\n",
      " 60%|███████████████████████████████████████████████▏                              | 699/1156 [00:05<00:03, 137.77it/s]\u001b[A\n",
      " 74%|██████████████████████████████████████████████████████████                    | 861/1156 [00:05<00:01, 189.88it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1156/1156 [00:05<00:00, 211.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.801173\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.794856\n",
      "[3]\tvalid_0's auc: 0.797272\n",
      "[4]\tvalid_0's auc: 0.789274\n",
      "[5]\tvalid_0's auc: 0.791944\n",
      "[6]\tvalid_0's auc: 0.783664\n",
      "[7]\tvalid_0's auc: 0.786969\n",
      "[8]\tvalid_0's auc: 0.775968\n",
      "[9]\tvalid_0's auc: 0.77441\n",
      "[10]\tvalid_0's auc: 0.774338\n",
      "[11]\tvalid_0's auc: 0.774395\n",
      "[12]\tvalid_0's auc: 0.774224\n",
      "[13]\tvalid_0's auc: 0.77369\n",
      "[14]\tvalid_0's auc: 0.773451\n",
      "[15]\tvalid_0's auc: 0.772031\n",
      "[16]\tvalid_0's auc: 0.771821\n",
      "[17]\tvalid_0's auc: 0.771055\n",
      "[18]\tvalid_0's auc: 0.762828\n",
      "[19]\tvalid_0's auc: 0.772427\n",
      "[20]\tvalid_0's auc: 0.759679\n",
      "[21]\tvalid_0's auc: 0.755307\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.801173\n",
      "[0.07471452 0.09459962 0.07471452 ... 0.21804365 0.21804365 0.21804365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Universidades:   0%|                                                                             | 0/1 [00:22<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.801173\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.794856\n",
      "[3]\tvalid_0's auc: 0.797272\n",
      "[4]\tvalid_0's auc: 0.789274\n",
      "[5]\tvalid_0's auc: 0.791944\n",
      "[6]\tvalid_0's auc: 0.783664\n",
      "[7]\tvalid_0's auc: 0.786969\n",
      "[8]\tvalid_0's auc: 0.775968\n",
      "[9]\tvalid_0's auc: 0.77441\n",
      "[10]\tvalid_0's auc: 0.774338\n",
      "[11]\tvalid_0's auc: 0.774395\n",
      "[12]\tvalid_0's auc: 0.774224\n",
      "[13]\tvalid_0's auc: 0.77369\n",
      "[14]\tvalid_0's auc: 0.773451\n",
      "[15]\tvalid_0's auc: 0.772031\n",
      "[16]\tvalid_0's auc: 0.771821\n",
      "[17]\tvalid_0's auc: 0.771055\n",
      "[18]\tvalid_0's auc: 0.762828\n",
      "[19]\tvalid_0's auc: 0.772427\n",
      "[20]\tvalid_0's auc: 0.759679\n",
      "[21]\tvalid_0's auc: 0.755307\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.801173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (3) is not the same as it was in training data (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8feb51f301b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m                        early_stopping_rounds=20)\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2413\u001b[1;33m         return predictor.predict(data, num_iteration,\n\u001b[0m\u001b[0;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2415\u001b[0m                                  data_has_header, is_reshape)\n",
      "\u001b[1;32mc:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length of pre-allocated predict array\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[0mout_num_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterPredictForMat(\n\u001b[0m\u001b[0;32m    595\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                 \u001b[0mptr_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\core i7 ultimate\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (3) is not the same as it was in training data (4)."
     ]
    }
   ],
   "source": [
    "universidades = ['ESPOL']\n",
    "predictionsDic = {}\n",
    "cont=0\n",
    "for univ in tqdm(universidades,desc='Universidades'):\n",
    "  archivo_edges = \"data/componente_gigante/coauthors-edgesCG-\"+univ+\".csv\"\n",
    "  archivo_nodes = \"data/componente_gigante/coauthors-nodesCG-\"+univ+\".csv\"\n",
    "  coau_df = pd.read_csv(archivo_edges,delimiter=\";\")\n",
    "  nodos_df = pd.read_csv(archivo_nodes,delimiter=\";\")\n",
    "  G = nx.from_pandas_edgelist(coau_df,\"Source\",\"Target\",['Weight','Year'],create_using=nx.Graph())\n",
    "  nodos = list(G.nodes)\n",
    "  #Obteniendo dataframe de pares de nodos que no tienen coneccion\n",
    "\n",
    "  adj_G = nx.to_numpy_matrix(G, nodelist = nodos)\n",
    "  all_unconnected_pairs = []\n",
    "\n",
    "  offset = 0\n",
    "  for i in range(adj_G.shape[0]):\n",
    "    for j in range(offset,adj_G.shape[1]):\n",
    "      if i != j:\n",
    "            if adj_G[i,j] == 0:\n",
    "              all_unconnected_pairs.append((nodos[i],nodos[j]))\n",
    "\n",
    "    offset = offset + 1\n",
    "\n",
    "  node_1_unlinked = [i[0] for i in all_unconnected_pairs]\n",
    "  node_2_unlinked = [i[1] for i in all_unconnected_pairs]\n",
    "\n",
    "  #Creando dataframe para almacenar a los pares de nodos no conectados que se recogieron\n",
    "  data = pd.DataFrame({'Source':node_1_unlinked,'Target':node_2_unlinked})\n",
    "  data['Weight'] = 0\n",
    "  data['link'] = 0\n",
    "\n",
    "  indices = range(len(data['Source']))\n",
    "  #Separando el dataframe en datos para train y para test\n",
    "  #(se busca un numero no muy grande de datos de pares que no tienen coneccion en los datos para entrenar, para\n",
    "  #evitar que los datos de entrenamiento esten desbalanceados)\n",
    "\n",
    "  if len(indices) > len(coau_df['Source'])*5:\n",
    "    _, indices = train_test_split(indices,test_size=0.15,random_state=73)\n",
    "  removeIn, noRemoveIn = train_test_split(indices,test_size=0.25,random_state=32)\n",
    "\n",
    "  test= data.copy()\n",
    "  test = test.loc[noRemoveIn]\n",
    "\n",
    "  data = data.loc[removeIn]\n",
    "\n",
    "  #Trabajando con los pares de nodos que si estan conectados\n",
    "\n",
    "  #Obteniendo lista de los links que se pueden borrar (que no eliminan nodos, o dividen al grafo en mas de una componente) y que\n",
    "  #estan despues del año establecido\n",
    "\n",
    "  year = 2018\n",
    "  initial_node_count = len(G.nodes)\n",
    "\n",
    "  coau_df_temp = coau_df.copy()\n",
    "\n",
    "  omissible_links_index = []\n",
    "  for i in tqdm(coau_df.index.values):\n",
    "      if G.adj[coau_df.values[i,0]][coau_df.values[i,1]]['Year']>=year:\n",
    "          # Eliminar una arista y construir un nuevo grafo sin esa unica arista\n",
    "          G_temp = nx.from_pandas_edgelist(coau_df_temp.drop(index=i), \"Source\", \"Target\",[\"Weight\"], create_using=nx.Graph())\n",
    "\n",
    "          # Verificando que al eliminar este par, no parte el grafo, y que el numero de nodos siga siendo el mismo\n",
    "\n",
    "          if (nx.number_connected_components(G_temp) == 1) and (len(G_temp.nodes) == initial_node_count):\n",
    "              omissible_links_index.append(i)\n",
    "              coau_df_temp = coau_df_temp.drop(i)\n",
    "\n",
    "  #creando dataframe de edges que se pueden remover\n",
    "\n",
    "  coau_df_temp2 = coau_df.copy()\n",
    "  coau_df_temp2[\"link\"]=1\n",
    "\n",
    "  #Separando dataframe en datos para train y test\n",
    "\n",
    "  testlinks = coau_df_temp2.loc[omissible_links_index]\n",
    "  coau_df_temp = coau_df_temp2.drop(index=omissible_links_index)\n",
    "\n",
    "  data = data.append(coau_df_temp[['Source', 'Target', 'link','Weight']], ignore_index=True)\n",
    "  data[\"Weight\"] = data[\"Weight\"].astype('int64')\n",
    "\n",
    "  test = test.append(testlinks[['Source', 'Target', 'link','Weight']], ignore_index=True)\n",
    "\n",
    "\n",
    "  #Creando nuevo grafo sin los links eliminados\n",
    "  G_data = nx.from_pandas_edgelist(coau_df_temp, \"Source\", \"Target\",[\"Weight\"], create_using=nx.Graph())\n",
    "\n",
    "  #SacandoFeatures:\n",
    "  Xtrain =[]\n",
    "  Ytrain =[]\n",
    "  for i in data.values:\n",
    "      Xtrain.append([len(commonNeighbors(G_data,i[0],i[1])),jaccardCoeff(G_data,i[0],i[1]),\n",
    "                     adamicAdar(G_data,i[0],i[1]),commonKeywords(nodos_df,i[0],i[1])])\n",
    "      Ytrain.append(i[3])\n",
    "  Xtrain = np.array(Xtrain)\n",
    "  Ytrain = np.array(Ytrain)\n",
    "\n",
    "  Xtest = []\n",
    "  Ytest = []\n",
    "  for i in test.values:\n",
    "      Xtest.append([len(commonNeighbors(G_data,i[0],i[1])),jaccardCoeff(G_data,i[0],i[1]),\n",
    "                    adamicAdar(G_data,i[0],i[1]),commonKeywords(nodos_df,i[0],i[1])])\n",
    "      Ytest.append(i[3])\n",
    "\n",
    "  Xtest = np.array(Xtest)\n",
    "  Ytest = np.array(Ytest)\n",
    "\n",
    "  #Prediciendo\n",
    "  lista = ['CommonNeighbors',\"JaccardCoeff\",\"AdamicAdar\",\"CommonKeywords\"]\n",
    "  lista = np.array(lista)\n",
    "  l = [True]*len(lista)\n",
    "  predictionsDic[univ] ={}\n",
    "  for i in range(2**len(lista)-1):\n",
    "    \n",
    "    lr = LogisticRegression(class_weight=\"balanced\")\n",
    "    lr.fit(Xtrain[:,l], Ytrain)\n",
    "\n",
    "    predictions = lr.predict(Xtest[:,l])\n",
    "    t = \"-\".join(lista[l])\n",
    "    \n",
    "    predictionsDic[univ][t] = {\n",
    "            'regresionLogistica':{\n",
    "                'accuracy':accuracy_score(Ytest,predictions),\n",
    "                'roc_auc':roc_auc_score(Ytest, predictions),\n",
    "                'recall':recall_score(Ytest,predictions),\n",
    "                'precision':precision_score(Ytest,predictions)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "                \n",
    "    clf = SVC(gamma='scale')\n",
    "\n",
    "    clf.fit(Xtrain[:,l], Ytrain)\n",
    "    predictions = clf.predict(Xtest[:,l])\n",
    "\n",
    "    predictionsDic[univ][t]['SVC'] = {\n",
    "        'accuracy':accuracy_score(Ytest,predictions),\n",
    "        'roc_auc':roc_auc_score(Ytest, predictions),\n",
    "        'recall':recall_score(Ytest,predictions),\n",
    "        'precision':precision_score(Ytest,predictions)\n",
    "    }\n",
    "\n",
    "    bagging = BaggingClassifier(base_estimator=LogisticRegression(class_weight=\"balanced\"),n_estimators=10, random_state=0).fit(Xtrain[:,l], Ytrain)\n",
    "    predictions = bagging.predict(Xtest[:,l])\n",
    "\n",
    "    predictionsDic[univ][t]['Bagging'] = {\n",
    "        'accuracy':accuracy_score(Ytest,predictions),\n",
    "        'roc_auc':roc_auc_score(Ytest, predictions),\n",
    "        'recall':recall_score(Ytest,predictions),\n",
    "        'precision':precision_score(Ytest,predictions)\n",
    "    }\n",
    "    l = contador(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1361,
     "status": "ok",
     "timestamp": 1589243074818,
     "user": {
      "displayName": "Alex Velez Llaque",
      "photoUrl": "",
      "userId": "11111465116901712450"
     },
     "user_tz": 300
    },
    "id": "zvuACH6U-Bz4",
    "outputId": "970d2134-1038-4824-c2f3-0c0015cc4a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESPOL': {'CommonNeighbors-JaccardCoeff-AdamicAdar-CommonKeywords': {'regresionLogistica': {'accuracy': 0.9418632936025298,\n",
       "    'roc_auc': 0.7497123736064298,\n",
       "    'recall': 0.5112781954887218,\n",
       "    'precision': 0.8225806451612904},\n",
       "   'SVC': {'accuracy': 0.9053758209681343,\n",
       "    'roc_auc': 0.5181235011018926,\n",
       "    'recall': 0.03759398496240601,\n",
       "    'precision': 0.75},\n",
       "   'Bagging': {'accuracy': 0.9418632936025298,\n",
       "    'roc_auc': 0.7497123736064298,\n",
       "    'recall': 0.5112781954887218,\n",
       "    'precision': 0.8225806451612904},\n",
       "   'LightGBM': {'accuracy': 0.9029433227925079,\n",
       "    'roc_auc': 0.5,\n",
       "    'recall': 0.0,\n",
       "    'precision': 0.0}},\n",
       "  'JaccardCoeff-AdamicAdar-CommonKeywords': {'regresionLogistica': {'accuracy': 0.940403794697154,\n",
       "    'roc_auc': 0.7421935766139487,\n",
       "    'recall': 0.49624060150375937,\n",
       "    'precision': 0.8181818181818182},\n",
       "   'SVC': {'accuracy': 0.9068353198735101,\n",
       "    'roc_auc': 0.5256422980943739,\n",
       "    'recall': 0.05263157894736842,\n",
       "    'precision': 0.8076923076923077},\n",
       "   'Bagging': {'accuracy': 0.9421065434200925,\n",
       "    'roc_auc': 0.7509655064385101,\n",
       "    'recall': 0.5137844611528822,\n",
       "    'precision': 0.8232931726907631}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de LinkPredictionU.ipynb",
   "provenance": [
    {
     "file_id": "1R9Q1z5q929ZCBL9QBeaB4qlirdKKlMZZ",
     "timestamp": 1589245463835
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
